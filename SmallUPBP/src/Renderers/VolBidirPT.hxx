/*
 * Copyright (C) 2014, Petr Vevoda, Martin Sik (http://cgg.mff.cuni.cz/~sik/), 
 * Tomas Davidovic (http://www.davidovic.cz), Iliyan Georgiev (http://www.iliyan.com/), 
 * Jaroslav Krivanek (http://cgg.mff.cuni.cz/~jaroslav/)
 *
 * Permission is hereby granted, free of charge, to any person obtaining
 * a copy of this software and associated documentation files (the "Software"),
 * to deal in the Software without restriction, including without limitation
 * the rights to use, copy, modify, merge, publish, distribute, sublicense,
 * and/or sell copies of the Software, and to permit persons to whom
 * the Software is furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be included
 * in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
 * IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
 * DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE
 * OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 *
 * (The above is MIT License: http://en.wikipedia.origin/wiki/MIT_License)
 */

#ifndef __VOLBIDIRPT_HXX__
#define __VOLBIDIRPT_HXX__

#include <vector>
#include <cmath>

#include "../Path/Bsdf.hxx"
#include "Renderer.hxx"

class VolBidirPT : public AbstractRenderer
{
    struct MisData
	{
		float mPdfAInv;            // Inverse of forward PDF
		float mRevPdfA;            // Reverse PDF
		float mRevPdfAWithoutBsdf; // Reverse PDF without PDF of sampling BSDF, needed for light vertices only
		bool  mIsDelta;            // Whether the vertex is on a delta surface
		bool  mIsOnLightSource;    // Whether the vertex is on a light source
		bool  mIsSpecular;         // Whether the event sampled at the vertex was specular
	};
	
	// The sole point of this structure is to make carrying around the ray baggage easier.
    struct SubPathState
    {
        Pos   mOrigin;             // Path origin
        Dir   mDirection;          // Where to go next
        Rgb   mThroughput;         // Path throughput           
        uint  mPathLength    : 30; // Number of path segments, including this
        uint  mIsFiniteLight :  1; // Just generated by finite light
		bool  mLastSpecular;       // Last sampled event was specular
		float mLastPdfWInv;        // PDF of the last sampled direction

		BoundaryStack mBoundaryStack; // Stack of crossed boundaries		
    };

    // Path vertex, used for connection
    struct PathVertex
    {		
		Pos   mHitpoint;   // Position of the vertex
        Rgb   mThroughput; // Path throughput (including emission)
        uint  mPathLength; // Number of segments between source and vertex
		bool  mInMedium;   // Vertex in participating medium, not on surface
		bool  mConnectable;// Whether this vertex can be used in vertex connection         
        BSDF  mBSDF;       // Stores all required local information, including incoming direction

		MisData mMisData;  // Data needed for MIS weights computation
    };

public:

	enum AlgorithmType
    {
        kLT = 0, // light tracing
		kPTdir,  // direct path tracing
		kPTls,   // path tracing with light sampling
		kPTmis,  // path tracing with MIS
		kBPT     // bidirectional path tracing
    };

    VolBidirPT(
        const Scene&  aScene,
		AlgorithmType aAlgorithm,
        int           aSeed = 1234
    ) :
        AbstractRenderer(aScene),
		mAlgorithm(aAlgorithm),
        mRng(aSeed)
	{
		// Because of static mCameraVerticesMisData size
		UPBP_ASSERT(mMaxPathLength < 50);
    }

    virtual void RunIteration(int aIteration)
    {
		// Get path count, one path for each pixel
        const int resX = int(mScene.mCamera.mResolution.get(0));
        const int resY = int(mScene.mCamera.mResolution.get(1));
        const int pathCount = resX * resY;

		// While we have the same number of pixels (camera paths)
        // and light paths, we do keep them separate for clarity reasons
        mScreenPixelCount  = float(pathCount);
        mLightSubPathCount = float(pathCount);

        // Clear path ends, nothing ends anywhere
        mPathEnds.resize(pathCount);
        memset(&mPathEnds[0], 0, mPathEnds.size() * sizeof(int));

        // Remove all light vertices and reserve space for some		
		mLightVertices.reserve(pathCount * mMaxPathLength);
        mLightVertices.clear();

        //////////////////////////////////////////////////////////////////////////
        // Generate light paths
        //////////////////////////////////////////////////////////////////////////
		
		// If there are no lights, only one path segment is allowed or pure path tracing is used, light tracing step is skipped
		if (mScene.GetLightCount() > 0 && mMaxPathLength > 1 && (mAlgorithm == kLT || mAlgorithm == kBPT))
			for (int pathIdx = 0; pathIdx < pathCount; pathIdx++)
        {			
			// Generate light path origin and direction
			SubPathState lightState;
            GenerateLightSample(lightState);

			// In attenuating media the ray can never travel from infinity
			if (!lightState.mIsFiniteLight && !mScene.GetGlobalMediumPtr()->GetAttenuationCoef(lightState.mOrigin).isBlackOrNegative())
				continue;

			// We assume that the light is on surface
			bool originInMedium = false;

            //////////////////////////////////////////////////////////////////////////
            // Trace light path
            for (;; ++lightState.mPathLength)
            {
                // Prepare ray
				Ray ray(lightState.mOrigin, lightState.mDirection);
                Isect isect(1e36f);

				// Trace ray
				mVolumeSegments.clear();
				if (!mScene.Intersect(ray, originInMedium ? AbstractMedium::kOriginInMedium : 0, mRng, isect, lightState.mBoundaryStack, mVolumeSegments))
                    break;

				UPBP_ASSERT(isect.IsValid());
				
				// Attenuate by intersected media (if any)
				float raySamplePdf(1.0f);
				float raySampleRevPdf(1.0f);
				if (!mVolumeSegments.empty())
				{					
					// PDF
					raySamplePdf = VolumeSegment::AccumulatePdf(mVolumeSegments);
					UPBP_ASSERT(raySamplePdf > 0);

					// Reverse PDF
					raySampleRevPdf = VolumeSegment::AccumulateRevPdf(mVolumeSegments);
					UPBP_ASSERT(raySampleRevPdf > 0);
					
					// Attenuation
					lightState.mThroughput *= VolumeSegment::AccumulateAttenuationWithoutPdf(mVolumeSegments) / raySamplePdf;					
				}

				if (lightState.mThroughput.isBlackOrNegative()) 
					break;

                // Prepare scattering function at the hitpoint (BSDF/phase depending on whether the hitpoint is at surface or in media, the isect knows)
				BSDF bsdf(ray, isect, mScene, BSDF::kFromLight, mScene.RelativeIOR(isect, lightState.mBoundaryStack));
            
				if (!bsdf.IsValid()) // e.g. hitting surface too parallel with tangent plane
					break;

				// Compute hitpoint
                const Pos hitPoint = ray.origin + ray.direction * isect.mDist;

				originInMedium = isect.IsInMedium();

				// Store vertex

				PathVertex lightVertex;
				lightVertex.mHitpoint    = hitPoint;
				lightVertex.mThroughput  = lightState.mThroughput;
				lightVertex.mPathLength  = lightState.mPathLength;
				lightVertex.mInMedium    = originInMedium;
				lightVertex.mConnectable = !bsdf.IsDelta();
				lightVertex.mBSDF        = bsdf;				

				// Infinite lights use MIS handled via solid angle integration, so do not divide by the distance for such lights
				const float distSq = (lightState.mPathLength > 1 || lightState.mIsFiniteLight == 1) ? Utils::sqr(isect.mDist) : 1.0f;
				lightVertex.mMisData.mPdfAInv            = lightState.mLastPdfWInv * distSq / (raySamplePdf * std::abs(bsdf.CosThetaFix()));	
				lightVertex.mMisData.mRevPdfA            = 1.0f;
				lightVertex.mMisData.mRevPdfAWithoutBsdf = lightVertex.mMisData.mRevPdfA;
				lightVertex.mMisData.mIsDelta            = bsdf.IsDelta();
				lightVertex.mMisData.mIsOnLightSource    = false;
				lightVertex.mMisData.mIsSpecular         = false;

				// Update reverse PDFs of the previous vertex
				mLightVertices.back().mMisData.mRevPdfA           *= raySampleRevPdf / distSq;
				mLightVertices.back().mMisData.mRevPdfAWithoutBsdf = mLightVertices.back().mMisData.mRevPdfA;

				mLightVertices.push_back(lightVertex);

				// Connect to camera, unless scattering function is purely specular
				if (!bsdf.IsDelta())
				{
                    if (lightState.mPathLength + 1 >= mMinPathLength)
                        ConnectToCamera(pathIdx, lightState, hitPoint, bsdf);
                }

                // Terminate if the path would become too long after scattering
                if (lightState.mPathLength + 2 > mMaxPathLength)
                    break;

                // Continue random walk
				if (!SampleScattering(bsdf, hitPoint, isect, lightState, mLightVertices.back().mMisData, mLightVertices.at(mLightVertices.size() - 2).mMisData))
                    break;
            }

            mPathEnds[pathIdx] = (int)mLightVertices.size();
        }

        //////////////////////////////////////////////////////////////////////////
        // Generate camera paths
        //////////////////////////////////////////////////////////////////////////

        // Unless rendering with traditional light tracing
		if (mAlgorithm != kLT)
			for (int pathIdx = 0; pathIdx < pathCount; ++pathIdx)
        {
			// Generate camera path origin and direction			
			SubPathState cameraState;
            const Vec2f screenSample = GenerateCameraSample(pathIdx, cameraState);
            Rgb color(0);

			// We assume that the camera is on surface
			bool originInMedium = false;

            //////////////////////////////////////////////////////////////////////
            // Trace camera path
            for(;; ++cameraState.mPathLength)
            {
                // Prepare ray
                Ray ray(cameraState.mOrigin, cameraState.mDirection);
                Isect isect(1e36f);

                // Trace ray
				mVolumeSegments.clear();
				if (!mScene.Intersect(ray, originInMedium ? AbstractMedium::kOriginInMedium : 0, mRng, isect, cameraState.mBoundaryStack, mVolumeSegments))
                {					
					// In attenuating media the ray can never travel to infinity
					//UPBP_ASSERT(!mScene.GetGlobalMediumPtr()->HasAttenuation());
					
					// We cannot end yet
					if (cameraState.mPathLength < mMinPathLength) 
						break;					
									
					// Get background light					
					const BackgroundLight* background = mScene.GetBackground();
					if (!background) 
						break;

					// In attenuating media the ray can never travel to infinity
					if (mScene.GetGlobalMediumPtr()->HasAttenuation())
						break;

					// Stop if we are in the light sampling mode and could have sampled this light last time in the next event estimation
					if (mAlgorithm == kPTls && cameraState.mPathLength > 1 && !cameraState.mLastSpecular) 
						break;

					// Attenuate by intersected media (if any)
					float raySamplePdf(1.0f);
					float raySampleRevPdf(1.0f);
					if (!mVolumeSegments.empty())
					{
						// PDF
						raySamplePdf = VolumeSegment::AccumulatePdf(mVolumeSegments);
						UPBP_ASSERT(raySamplePdf > 0);

						// Reverse PDF
						raySampleRevPdf = VolumeSegment::AccumulateRevPdf(mVolumeSegments);
						UPBP_ASSERT(raySampleRevPdf > 0);

						// Attenuation
						cameraState.mThroughput *= VolumeSegment::AccumulateAttenuationWithoutPdf(mVolumeSegments) / raySamplePdf;					
					}				

					if (cameraState.mThroughput.isBlackOrNegative()) 
						break;

					// Update affected MIS data
					mCameraVerticesMisData[cameraState.mPathLength].mPdfAInv         = cameraState.mLastPdfWInv / raySamplePdf;
					mCameraVerticesMisData[cameraState.mPathLength].mRevPdfA         = 1.0f;
					mCameraVerticesMisData[cameraState.mPathLength].mIsDelta         = false;
					mCameraVerticesMisData[cameraState.mPathLength].mIsOnLightSource = true;
					mCameraVerticesMisData[cameraState.mPathLength].mIsSpecular      = false;
					mCameraVerticesMisData[cameraState.mPathLength - 1].mRevPdfA    *= raySampleRevPdf;

					// Accumulate contribution
					color += cameraState.mThroughput *
						GetLightRadiance(mScene.GetBackground(), cameraState, Pos(0));

					break;
				}

				UPBP_ASSERT(isect.IsValid());

				// Attenuate by intersected media (if any)
				float raySamplePdf(1.0f);
				float raySampleRevPdf(1.0f);
				if (!mVolumeSegments.empty())
				{
					// PDF
					raySamplePdf = VolumeSegment::AccumulatePdf(mVolumeSegments);
					UPBP_ASSERT(raySamplePdf > 0);

					// Reverse PDF
					raySampleRevPdf = VolumeSegment::AccumulateRevPdf(mVolumeSegments);
					UPBP_ASSERT(raySampleRevPdf > 0);

					// Attenuation
					cameraState.mThroughput *= VolumeSegment::AccumulateAttenuationWithoutPdf(mVolumeSegments) / raySamplePdf;					
				}				

				if (cameraState.mThroughput.isBlackOrNegative()) 
					break;

				// Prepare scattering function at the hitpoint (BSDF/phase depending on whether the hitpoint is at surface or in media, the isect knows)
				BSDF bsdf(ray, isect, mScene, BSDF::kFromCamera, mScene.RelativeIOR(isect, cameraState.mBoundaryStack));
				
				if (!bsdf.IsValid()) // e.g. hitting surface too parallel with tangent plane
					break;

				// Compute hitpoint
				Pos hitPoint = ray.origin + ray.direction * isect.mDist;

				originInMedium = isect.IsInMedium();

				// Update affected MIS data
				const float distSq = Utils::sqr(isect.mDist);
				mCameraVerticesMisData[cameraState.mPathLength].mPdfAInv         = cameraState.mLastPdfWInv * distSq / (raySamplePdf * std::abs(bsdf.CosThetaFix()));
				mCameraVerticesMisData[cameraState.mPathLength].mRevPdfA         = 1.0f;
				mCameraVerticesMisData[cameraState.mPathLength].mIsDelta         = bsdf.IsDelta();
				mCameraVerticesMisData[cameraState.mPathLength].mIsOnLightSource = isect.mLightID >= 0;
				mCameraVerticesMisData[cameraState.mPathLength].mIsSpecular      = false;
				mCameraVerticesMisData[cameraState.mPathLength - 1].mRevPdfA    *= raySampleRevPdf / distSq;

                // Light source has been hit; terminate afterwards, since
                // our light sources do not have reflective properties
				if (isect.mLightID >= 0)
                {
                    // We cannot end yet
					if (cameraState.mPathLength < mMinPathLength) 
						break;

					// Stop if we are in the light sampling mode and could have sampled this light last time in the next event estimation
					if (mAlgorithm == kPTls && cameraState.mPathLength > 1 && !cameraState.mLastSpecular) 
						break;
					
					// Get hit light
					const AbstractLight *light = mScene.GetLightPtr(isect.mLightID);
					UPBP_ASSERT(light);

					// Add its contribution
					color += cameraState.mThroughput *
						GetLightRadiance(light, cameraState, hitPoint);
                    
                    break;
                }

                // Terminate if eye sub-path is too long for connections or merging
                if (cameraState.mPathLength >= mMaxPathLength)
                    break;

                ////////////////////////////////////////////////////////////////
                // Vertex connection: Connect to a light source
				if (mAlgorithm != kPTdir && !bsdf.IsDelta() && cameraState.mPathLength + 1 >= mMinPathLength && mScene.GetLightCount() > 0)
				{
					color += cameraState.mThroughput *
						DirectIllumination(cameraState, hitPoint, bsdf);
				}

                ////////////////////////////////////////////////////////////////
                // Vertex connection: Connect to light vertices
				if (mAlgorithm == kBPT && !bsdf.IsDelta())
                {
                    // For VC, each light sub-path is assigned to a particular eye
                    // sub-path, as in traditional BPT. It is also possible to
                    // connect to vertices from any light path, but MIS should
                    // be revisited.
                    const Vec2i range(
                        (pathIdx == 0) ? 0 : mPathEnds[pathIdx-1],
                        mPathEnds[pathIdx]);

                    for (int i = range[0]; i < range[1]; i++)
                    {
                        const PathVertex &lightVertex = mLightVertices[i];

                        if (lightVertex.mPathLength + 1 +
                           cameraState.mPathLength < mMinPathLength)
                            continue;

                        // Light vertices are stored in increasing path length
                        // order; once we go above the max path length, we can
                        // skip the rest
                        if (lightVertex.mPathLength + 1 +
                           cameraState.mPathLength > mMaxPathLength)
                            break;

						// We store all light vertices in order to compute MIS weights but not all can be used for VC
						if (!lightVertex.mConnectable)
							continue;

						color += cameraState.mThroughput * lightVertex.mThroughput * ConnectVertices(pathIdx, lightVertex, bsdf, hitPoint, cameraState);
                    }
                }

				// Continue random walk
                if (!SampleScattering(bsdf, hitPoint, isect, cameraState, mCameraVerticesMisData[cameraState.mPathLength], mCameraVerticesMisData[cameraState.mPathLength - 1]))
                    break;
            }

            mFramebuffer.AddColor(screenSample, color);
        }

        mIterations++;
    }

private:    

    //////////////////////////////////////////////////////////////////////////
    // Camera tracing methods
    //////////////////////////////////////////////////////////////////////////

    // Generates new camera sample given a pixel index
    Vec2f GenerateCameraSample(
        const int    aPixelIndex,
        SubPathState &oCameraState)
    {
        const Camera &camera = mScene.mCamera;
        const int resX = int(camera.mResolution.get(0));
        const int resY = int(camera.mResolution.get(1));

        // Determine pixel (x, y)
        const int x = aPixelIndex % resX;
        const int y = aPixelIndex / resX;

        // Jitter pixel position
        const Vec2f sample = Vec2f(float(x), float(y)) + mRng.GetVec2f();

        // Generate ray
        const Ray primaryRay = camera.GenerateRay(sample);

        // Compute PDF conversion factor from area on image plane to solid angle on ray
        const float cosAtCamera = dot(camera.mDirection, primaryRay.direction);
        const float imagePointToCameraDist = camera.mImagePlaneDist / cosAtCamera;
        const float imageToSolidAngleFactor = Utils::sqr(imagePointToCameraDist) / cosAtCamera;

        // We put the virtual image plane at such a distance from the camera origin
        // that the pixel area is one and thus the image plane sampling PDF is 1.
        // The solid angle ray PDF is then equal to the conversion factor from
        // image plane area density to ray solid angle density
        const float cameraPdfW = imageToSolidAngleFactor;

        oCameraState.mOrigin       = primaryRay.origin;
        oCameraState.mDirection    = primaryRay.direction;
        oCameraState.mThroughput   = Rgb(1);		
        oCameraState.mPathLength   = 1;
		oCameraState.mLastSpecular = true;
		oCameraState.mLastPdfWInv  = mLightSubPathCount / cameraPdfW;

		// Init the boundary stack with the global medium and add enclosing material and medium if present
		mScene.InitBoundaryStack(oCameraState.mBoundaryStack);
		if (camera.mMatID != -1 && camera.mMedID != -1) mScene.AddToBoundaryStack(camera.mMatID, camera.mMedID, oCameraState.mBoundaryStack);

        return sample;
    }

    // Returns the radiance of a light source when hit by a random ray,
    // multiplied by MIS weight. Can be used for both Background and Area lights.
    Rgb GetLightRadiance(
        const AbstractLight *aLight,
        const SubPathState  &aCameraState,
        const Pos           &aHitpoint) const
    {
        // We sample lights uniformly
        const int   lightCount    = mScene.GetLightCount();
        const float lightPickProb = 1.f / lightCount;

        float directPdfA, emissionPdfW;
        const Rgb radiance = aLight->GetRadiance(mScene.mSceneSphere,
			aCameraState.mDirection, aHitpoint, &directPdfA, &emissionPdfW);

        if(radiance.isBlackOrNegative())
            return Rgb(0);

        // If we see light source directly from camera, no weighting is required
        if(aCameraState.mPathLength == 1)
            return radiance;

        directPdfA   *= lightPickProb;
        emissionPdfW *= lightPickProb;
		
		UPBP_ASSERT(directPdfA > 0);
		UPBP_ASSERT(emissionPdfW > 0);

        // MIS weight
		float misWeight = 1.f;
		if (mAlgorithm == kBPT)
		{
			UPBP_ASSERT(directPdfA > 0);
			const float wCamera = AccumulateCameraPathWeight(aCameraState.mPathLength, directPdfA, emissionPdfW / directPdfA);
			misWeight = 1.0f / (wCamera + 1.f);
		}
		else if (mAlgorithm == kPTmis && !aCameraState.mLastSpecular)
		{
			const float wCamera = directPdfA * mCameraVerticesMisData[aCameraState.mPathLength].mPdfAInv;
			misWeight = 1.0f / (wCamera + 1.f);
		}

        return misWeight * radiance;
    }

	// Connects camera vertex to randomly chosen light point.
    // Returns emitted radiance multiplied by path MIS weight.
    // Has to be called AFTER updating the MIS quantities.
    Rgb DirectIllumination(
		const SubPathState  &aCameraState,
        const Pos           &aHitpoint,
        const BSDF          &aCameraBSDF)
    {	
		// We sample lights uniformly
        const int   lightCount    = mScene.GetLightCount();
        const float lightPickProb = 1.f / lightCount;

        const int   lightID       = int(mRng.GetFloat() * lightCount);
        const Vec2f rndPosSamples = mRng.GetVec2f();

        const AbstractLight *light = mScene.GetLightPtr(lightID);
		UPBP_ASSERT(light);

		// Light in infinity in attenuating homogeneous global medium is always reduced to zero
		if (!light->IsFinite() && !mScene.GetGlobalMediumPtr()->GetAttenuationCoef(aHitpoint).isBlackOrNegative())
			return Rgb(0);

        Dir directionToLight;
        float distance;
        float directPdfW, emissionPdfW, cosAtLight;
        const Rgb radiance = light->Illuminate(mScene.mSceneSphere, aHitpoint,
            rndPosSamples, directionToLight, distance, directPdfW,
            &emissionPdfW, &cosAtLight);

        // If radiance == 0, other values are undefined, so shave to early exit
        if(radiance.isBlackOrNegative())
            return Rgb(0);

		UPBP_ASSERT(directPdfW > 0);
		UPBP_ASSERT(emissionPdfW > 0);
		UPBP_ASSERT(cosAtLight > 0);

		// Get BSDF factor at the last camera vertex
        float bsdfDirPdfW, bsdfRevPdfW, cosToLight;
        Rgb bsdfFactor = aCameraBSDF.Evaluate(directionToLight, cosToLight, &bsdfDirPdfW, &bsdfRevPdfW);

        if(bsdfFactor.isBlackOrNegative())
            return Rgb(0);

        const float continuationProbability = aCameraBSDF.ContinuationProb();
        
        // If the light is delta light, we can never hit it
        // by BSDF sampling, so the probability of this path is 0
        bsdfDirPdfW *= light->IsDelta() ? 0.f : continuationProbability;
        bsdfRevPdfW *= continuationProbability;

		UPBP_ASSERT(bsdfRevPdfW > 0);
		UPBP_ASSERT(cosToLight > 0);

        Rgb contrib(0);	

		// Test occlusion
		mVolumeSegments.clear();
		if (!mScene.Occluded(aHitpoint, directionToLight, distance, aCameraState.mBoundaryStack, aCameraBSDF.IsInMedium() ? AbstractMedium::kOriginInMedium : 0, mVolumeSegments))
		{							
			// Get attenuation from intersected media (if any)
			float nextRaySamplePdf(1.0f);
			float nextRaySampleRevPdf(1.0f);
			Rgb nextAttenuation(1.0f); 
			if (!mVolumeSegments.empty())
			{
				// PDF
				nextRaySamplePdf = VolumeSegment::AccumulatePdf(mVolumeSegments);
				UPBP_ASSERT(nextRaySamplePdf > 0);

				// Reverse PDF
				nextRaySampleRevPdf = VolumeSegment::AccumulateRevPdf(mVolumeSegments);
				UPBP_ASSERT(nextRaySampleRevPdf > 0);

				// Attenuation (without PDF!)
				nextAttenuation = VolumeSegment::AccumulateAttenuationWithoutPdf(mVolumeSegments);
				if (!nextAttenuation.isPositive())
					return Rgb(0);
			}

			// MIS weight
			float misWeight = 1.f;
			if (mAlgorithm == kBPT)
			{
				// For wCamera we need ratio = emissionPdfA / directPdfA,
				// with emissionPdfA being the product of the PDFs for choosing the
				// point on the light source and sampling the outgoing direction.
				// What we are given by the light source instead are emissionPdfW
				// and directPdfW. Converting to area PDFs and plugging into ratio:
				//    emissionPdfA = emissionPdfW * cosToLight / dist^2
				//    directPdfA   = directPdfW * cosAtLight / dist^2
				//    ratio = (emissionPdfW * cosToLight / dist^2) / (directPdfW * cosAtLight / dist^2)
				//    ratio = (emissionPdfW * cosToLight) / (directPdfW * cosAtLight)
				// Also note that both emissionPdfW and directPdfW should be
				// multiplied by lightPickProb, so it cancels out.
				UPBP_ASSERT(nextRaySampleRevPdf * emissionPdfW * cosToLight / (directPdfW * cosAtLight) > 0);
				const float wCamera = AccumulateCameraPathWeight(aCameraState.mPathLength, nextRaySampleRevPdf * emissionPdfW * cosToLight / (directPdfW * cosAtLight), bsdfRevPdfW);
				
				// Note that wLight is a ratio of area PDFs. But since both are on the
				// light source, their distance^2 and cosine terms cancel out.
				// Therefore we can write wLight as a ratio of solid angle PDFs,
				// both expressed w.r.t. the same shading point.
				const float wLight = light->IsDelta() ? 0 : (nextRaySamplePdf * bsdfDirPdfW) / (directPdfW * lightPickProb);
				misWeight = 1.0f / (wCamera + 1.f + wLight);
			}
			else if (mAlgorithm != kPTls && !light->IsDelta())										
				misWeight = Mis2(lightPickProb * directPdfW, bsdfDirPdfW * nextRaySamplePdf);			

			contrib = (misWeight * cosToLight / (lightPickProb * directPdfW)) * (radiance * nextAttenuation * bsdfFactor);						
		}

		if (contrib.isBlackOrNegative())
			return Rgb(0);

		return contrib;
    }

    // Connects an eye and a light vertex. Result multiplied by MIS weight, but
    // not multiplied by vertex throughputs. Has to be called AFTER updating MIS
    // constants. 'direction' is FROM eye TO light vertex.
    Rgb ConnectVertices(
        const int          aPathIdx,
		const PathVertex   &aLightVertex,
        const BSDF         &aCameraBSDF,
        const Pos          &aCameraHitpoint,
        const SubPathState &aCameraState)
    {
        // Get the connection
        Dir direction     = aLightVertex.mHitpoint - aCameraHitpoint;
        const float dist2 = direction.square();
        float  distance   = std::sqrt(dist2);
        direction        /= distance;

        // Evaluate BSDF at camera vertex
        float cosCamera, cameraBsdfDirPdfW, cameraBsdfRevPdfW;
        Rgb cameraBsdfFactor = aCameraBSDF.Evaluate(
            direction, cosCamera, &cameraBsdfDirPdfW,
            &cameraBsdfRevPdfW);

        if(cameraBsdfFactor.isBlackOrNegative())
            return Rgb(0);

        // Camera continuation probability (for Russian roulette)
        const float cameraCont = aCameraBSDF.ContinuationProb();
        cameraBsdfDirPdfW *= cameraCont;
        cameraBsdfRevPdfW *= cameraCont;
		UPBP_ASSERT(cameraBsdfDirPdfW > 0);
		UPBP_ASSERT(cameraBsdfRevPdfW > 0);

        // Evaluate BSDF at light vertex
        float cosLight, lightBsdfDirPdfW, lightBsdfRevPdfW;
        const Rgb lightBsdfFactor = aLightVertex.mBSDF.Evaluate(
            -direction, cosLight, &lightBsdfDirPdfW,
            &lightBsdfRevPdfW);

        if(lightBsdfFactor.isBlackOrNegative())
            return Rgb(0);

        // Light continuation probability (for Russian roulette)
        const float lightCont = aLightVertex.mBSDF.ContinuationProb();
        lightBsdfDirPdfW *= lightCont;
        lightBsdfRevPdfW *= lightCont;
		UPBP_ASSERT(lightBsdfDirPdfW > 0);
		UPBP_ASSERT(lightBsdfRevPdfW > 0);

        // Compute geometry term
        const float geometryTerm = cosLight * cosCamera / dist2;
        if(geometryTerm < 0)
            return Rgb(0);

        // Convert PDFs to area PDF
        const float cameraBsdfDirPdfA = PdfWtoA(cameraBsdfDirPdfW, distance, cosLight);
        const float lightBsdfDirPdfA  = PdfWtoA(lightBsdfDirPdfW,  distance, cosCamera);
		UPBP_ASSERT(cameraBsdfDirPdfA > 0);
		UPBP_ASSERT(lightBsdfDirPdfA > 0);

        uint raySamplingFlags = 0;
		if (aCameraBSDF.IsInMedium()) raySamplingFlags |= AbstractMedium::kOriginInMedium;
		if (aLightVertex.mInMedium)   raySamplingFlags |= AbstractMedium::kEndInMedium;

		// Test occlusion
		mVolumeSegments.clear();
		if (mScene.Occluded(aCameraHitpoint, direction, distance, aCameraState.mBoundaryStack, raySamplingFlags, mVolumeSegments))									  
            return Rgb(0);

		// Attenuate by intersected media (if any)
		float raySamplePdf(1.0f);
		float raySampleRevPdf(1.0f);
		Rgb mediaAttenuation(1.0f);
		if (!mVolumeSegments.empty())
		{
			// PDF
			raySamplePdf = VolumeSegment::AccumulatePdf(mVolumeSegments);
			UPBP_ASSERT(raySamplePdf > 0);

			// Reverse PDF
			raySampleRevPdf = VolumeSegment::AccumulateRevPdf(mVolumeSegments);
			UPBP_ASSERT(raySampleRevPdf > 0);

			// Attenuation (without PDF!)
			mediaAttenuation = VolumeSegment::AccumulateAttenuationWithoutPdf(mVolumeSegments);
			if (!mediaAttenuation.isPositive())
				return Rgb(0);
		}

		// MIS weight
		UPBP_ASSERT(raySampleRevPdf * lightBsdfDirPdfA > 0);
		const float wCamera = AccumulateCameraPathWeight(aCameraState.mPathLength, raySampleRevPdf * lightBsdfDirPdfA, cameraBsdfRevPdfW);
		UPBP_ASSERT(raySamplePdf * cameraBsdfDirPdfA > 0);
		const float wLight = AccumulateLightPathWeight(aPathIdx, aLightVertex.mPathLength, raySamplePdf * cameraBsdfDirPdfA, lightBsdfRevPdfW);
		const float misWeight = 1.f / (wCamera + 1.f + wLight);

		const Rgb contrib = (misWeight * geometryTerm) * cameraBsdfFactor * lightBsdfFactor * mediaAttenuation;

		if (contrib.isBlackOrNegative())
            return Rgb(0);

        return contrib;
    }

	// Accumulates PDF ratios of all sampling techniques along path originally sampled from light
	float AccumulateCameraPathWeight(int aPathLength, float aLastRevPdfA, float aNextToLastPartialRevPdfW) const
	{
		float weight = 0;
		float product = 1.0f;
		int lastIndex = aPathLength;
		int index = 0;

		// Zero vertex (on camera) is ignored (no chance hitting it)
		while (index < aPathLength)
		{
			// Two vertices of the current path segment (same if already at the first camera vertex)
			const MisData& current = mCameraVerticesMisData[lastIndex - index];
			const MisData& next    = index < aPathLength - 1 ? mCameraVerticesMisData[lastIndex - index - 1] : current;
			
			// Get reverse PDF
			float rev = index == 0 ? aLastRevPdfA : current.mRevPdfA;
			if (index == 1) 
				 rev *= aNextToLastPartialRevPdfW;

			UPBP_ASSERT(rev);
			
			// Get inverse of forward PDF
			float fwInv = current.mPdfAInv;
			UPBP_ASSERT(fwInv);
			
			// Compute ratio
			product *= (rev * fwInv);

			// Accumulate the ratio if none of the vertices sampled specular events
			if ((index == 0 || !current.mIsSpecular) && !next.mIsSpecular)			
				weight += product;		
			
			++index;
		}

		return weight;
	}

    //////////////////////////////////////////////////////////////////////////
    // Light tracing methods
    //////////////////////////////////////////////////////////////////////////

    // Samples light emission
    void GenerateLightSample(SubPathState &oLightState)
    {
        // We sample lights uniformly
        const int   lightCount    = mScene.GetLightCount();
        const float lightPickProb = 1.f / lightCount;

        const int   lightID       = int(mRng.GetFloat() * lightCount);
        const Vec2f rndDirSamples = mRng.GetVec2f();
        const Vec2f rndPosSamples = mRng.GetVec2f();

        const AbstractLight *light = mScene.GetLightPtr(lightID);
		UPBP_ASSERT(light);

        float emissionPdfW, directPdfA, cosLight;
        oLightState.mThroughput = light->Emit(mScene.mSceneSphere, rndDirSamples, rndPosSamples,
            oLightState.mOrigin, oLightState.mDirection,
            emissionPdfW, &directPdfA, &cosLight);

		emissionPdfW *= lightPickProb;
        directPdfA   *= lightPickProb;

		UPBP_ASSERT(emissionPdfW);
		UPBP_ASSERT(directPdfA);		

		// Store vertex

		PathVertex lightVertex;
		lightVertex.mHitpoint    = oLightState.mOrigin;
		lightVertex.mThroughput  = Rgb(1.0f);
		lightVertex.mPathLength  = 0;
		lightVertex.mInMedium    = false;
		lightVertex.mConnectable = false;			

		lightVertex.mMisData.mPdfAInv            = 1.0f / directPdfA;
		lightVertex.mMisData.mRevPdfA            = light->IsDelta() ? 0.0f : (light->IsFinite() ? cosLight : 1.f);
		lightVertex.mMisData.mRevPdfAWithoutBsdf = lightVertex.mMisData.mRevPdfA;
		lightVertex.mMisData.mIsDelta            = light->IsDelta();
		lightVertex.mMisData.mIsOnLightSource    = true;
		lightVertex.mMisData.mIsSpecular         = false;

		mLightVertices.push_back(lightVertex);

        		
		// Complete light path state initialization

        oLightState.mThroughput   /= emissionPdfW;
        oLightState.mPathLength    = 1;
        oLightState.mIsFiniteLight = light->IsFinite() ? 1 : 0;
		oLightState.mLastSpecular  = false;
		oLightState.mLastPdfWInv   = directPdfA / emissionPdfW;
		
		// Init the boundary stack with the global medium and add enclosing material and medium if present
		mScene.InitBoundaryStack(oLightState.mBoundaryStack);
		if (light->mMatID != -1 && light->mMedID != -1) mScene.AddToBoundaryStack(light->mMatID, light->mMedID, oLightState.mBoundaryStack);
    }

    // Computes contribution of light sample to camera by splatting is onto the
    // framebuffer. Multiplies by throughput (obviously, as nothing is returned).
    void ConnectToCamera(
		const int          aLightPathIdx,
        const SubPathState &aLightState,
        const Pos          &aHitpoint,
        const BSDF         &aLightBSDF)
    {
        // Get camera and direction to it
		const Camera &camera  = mScene.mCamera;
		Dir directionToCamera = camera.mOrigin - aHitpoint;

        // Check point is in front of camera
		if (dot(camera.mDirection, -directionToCamera) <= 0.f)
            return;

        // Check it projects to the screen (and where)
        const Vec2f imagePos = camera.WorldToRaster(aHitpoint);
        if (!camera.CheckRaster(imagePos))
            return;

        // Compute distance and normalize direction to camera
        const float distEye2 = directionToCamera.square();
        const float distance = std::sqrt(distEye2);
        directionToCamera   /= distance;

        // Get the BSDF factor
        float cosToCamera, bsdfDirPdfW, bsdfRevPdfW;
        Rgb bsdfFactor = aLightBSDF.Evaluate(directionToCamera, cosToCamera, &bsdfDirPdfW, &bsdfRevPdfW);		  

		if (bsdfFactor.isBlackOrNegative())
            return;

		bsdfRevPdfW *= aLightBSDF.ContinuationProb();

		UPBP_ASSERT(bsdfDirPdfW > 0);
		UPBP_ASSERT(bsdfRevPdfW > 0);
		UPBP_ASSERT(cosToCamera > 0);        

        // Compute PDF conversion factor from image plane area to surface area
		const float cosAtCamera = dot(camera.mDirection, -directionToCamera);
        const float imagePointToCameraDist = camera.mImagePlaneDist / cosAtCamera;
        const float imageToSolidAngleFactor = Utils::sqr(imagePointToCameraDist) / cosAtCamera;
        const float imageToSurfaceFactor = imageToSolidAngleFactor * std::abs(cosToCamera) / Utils::sqr(distance);

        // We put the virtual image plane at such a distance from the camera origin
        // that the pixel area is one and thus the image plane sampling PDF is 1.
        // The area PDF of aHitpoint as sampled from the camera is then equal to
        // the conversion factor from image plane area density to surface area density
        const float cameraPdfA = imageToSurfaceFactor;
		UPBP_ASSERT(cameraPdfA > 0);

        const float surfaceToImageFactor = 1.f / imageToSurfaceFactor;

		// Test occlusion
		mVolumeSegments.clear();
		if (!mScene.Occluded(aHitpoint, directionToCamera, distance, aLightState.mBoundaryStack, aLightBSDF.IsInMedium() ? AbstractMedium::kOriginInMedium : 0, mVolumeSegments))
        {				
			// Get attenuation from intersected media (if any)
			float raySampleRevPdf(1.0f);
			Rgb mediaAttenuation(1.0f);
			if (!mVolumeSegments.empty())
			{
				// Reverse PDF
				raySampleRevPdf = VolumeSegment::AccumulateRevPdf(mVolumeSegments);
				UPBP_ASSERT(raySampleRevPdf > 0);

				// Attenuation (without PDF!)
				mediaAttenuation = VolumeSegment::AccumulateAttenuationWithoutPdf(mVolumeSegments);
				if (!mediaAttenuation.isPositive())
					return;
			}

			// Compute MIS weight if doing BPT
			float misWeight = 1.f;
			if (mAlgorithm == kBPT)
			{
				UPBP_ASSERT(raySampleRevPdf * cameraPdfA > 0);
				const float wLight = AccumulateLightPathWeight(aLightPathIdx, aLightState.mPathLength, raySampleRevPdf * cameraPdfA, bsdfRevPdfW) / mLightSubPathCount;
				misWeight = 1.0f / (1.f + wLight);
			}

			// We divide the contribution by surfaceToImageFactor to convert the (already
			// divided) PDF from surface area to image plane area, w.r.t. which the
			// pixel integral is actually defined. We also divide by the number of samples
			// this technique makes, which is equal to the number of light sub-paths
			Rgb contrib = misWeight * aLightState.mThroughput * bsdfFactor * mediaAttenuation / (mLightSubPathCount * surfaceToImageFactor);
			
			if (contrib.isBlackOrNegative())
				return;

            mFramebuffer.AddColor(imagePos, contrib);
        }
    }

	// Accumulates PDF ratios of all sampling techniques along path originally sampled from light
	float AccumulateLightPathWeight(
		const int   aPathIndex, 
		const int   aPathLength, 
		const float aLastRevPdfA, 
		const float aNextToLastPartialRevPdfW) const
	{
		float weight = 0;
		float product = 1.0f;
		int lastIndex = (aPathIndex == 0) ? aPathLength : mPathEnds[aPathIndex - 1] + aPathLength;
		int index = 0;

		while (index <= aPathLength)
		{
			// Two vertices of the current path segment (same if already at light)
			const MisData& current = mLightVertices.at(lastIndex - index).mMisData;
			const MisData& next    = index < aPathLength ? mLightVertices.at(lastIndex - index - 1).mMisData : current;
			
			// Get reverse PDF
			float rev = current.mRevPdfA;
			if (index == 0) 
				  rev = aLastRevPdfA;
			else if (index == 1) 
				  rev = current.mRevPdfAWithoutBsdf * aNextToLastPartialRevPdfW;	
	
			UPBP_ASSERT(rev || (current.mIsOnLightSource && current.mIsDelta));

			if (rev == 0) 
				break;
			
			// Get inverse of forward PDF
			float fwInv = current.mPdfAInv;
			UPBP_ASSERT(fwInv);
			
			// Compute ratio
			product *= (rev * fwInv);

			// Accumulate the ratio if none of the vertices sampled specular events
			if ((index == 0 || !current.mIsSpecular) && !next.mIsSpecular)			
				weight += product;		
			
			++index;
		}

		return weight;
	}

	//////////////////////////////////////////////////////////////////////////
    // Common methods
    //////////////////////////////////////////////////////////////////////////

	// MIS power, we use balance heuristic
    float Mis(float aPdf) const
    {
        //return std::pow(aPdf, /*power*/);
        return aPdf;
    }

	// MIS weight for 2 PDFs
    float Mis2(
        float aSamplePdf,
        float aOtherPdf) const
    {
        return Mis(aSamplePdf) / (Mis(aSamplePdf) + Mis(aOtherPdf));
    }

    // Samples a scattering direction camera/light sample according to BSDF.
    // Returns false for termination
    bool SampleScattering(
		const BSDF    &aBSDF,
        const Pos     &aHitPoint,
		const Isect   &aIsect,
        SubPathState  &aoState,
		MisData       &aoCurrentMisData,
		MisData       &aoPreviousMisData)
    {	
		// Sample scattering function		
		
        Dir   rndTriplet  = mRng.GetVec3f(); // x,y for direction, z for component. No rescaling happens
        float bsdfDirPdfW, cosThetaOut;
        uint  sampledEvent;

        Rgb bsdfFactor = aBSDF.Sample(rndTriplet, aoState.mDirection,
            bsdfDirPdfW, cosThetaOut, &sampledEvent);

        if (bsdfFactor.isBlackOrNegative())
            return false;

		bool specular = (sampledEvent & BSDF::kSpecular) != 0;

        // If we sampled specular event, then the reverse probability
        // cannot be evaluated, but we know it is exactly the same as
        // forward probability, so just set it. If non-specular event happened,
        // we evaluate the PDF
        float bsdfRevPdfW = bsdfDirPdfW;
        if (!specular)
			bsdfRevPdfW = aBSDF.Pdf(aoState.mDirection, BSDF::kReverse);

		UPBP_ASSERT(bsdfDirPdfW);
		UPBP_ASSERT(bsdfRevPdfW);

        // Russian roulette
        const float contProb = aBSDF.ContinuationProb();        
		if (contProb == 0 || (contProb < 1.0f && mRng.GetFloat() > contProb))
            return false;

        bsdfDirPdfW *= contProb;
        bsdfRevPdfW *= contProb;

		const float bsdfDirPdfWInv = 1.0f / bsdfDirPdfW;

		// Update path state

		aoState.mOrigin       = aHitPoint;
		aoState.mThroughput  *= bsdfFactor * (cosThetaOut * bsdfDirPdfWInv);
		aoState.mLastPdfWInv  = bsdfDirPdfWInv;
		aoState.mLastSpecular = specular;

		// Switch medium on refraction
		if ((sampledEvent & BSDF::kRefract) != 0)
			mScene.UpdateBoundaryStackOnRefract(aIsect, aoState.mBoundaryStack);		
		
		// Update affected MIS data
		aoCurrentMisData.mRevPdfA           *= cosThetaOut;
		aoCurrentMisData.mRevPdfAWithoutBsdf = aoCurrentMisData.mRevPdfA;
		aoCurrentMisData.mIsSpecular         = specular;
		aoPreviousMisData.mRevPdfA          *= bsdfRevPdfW;

        return true;
    }

private:

    float mScreenPixelCount;  // Number of pixels
    float mLightSubPathCount; // Number of light sub-paths

    std::vector<PathVertex> mLightVertices; // Stored light vertices
	MisData mCameraVerticesMisData[50];     // Stored MIS data for camera vertices (we don't need store whole vertices as for light paths)
	
	// Path segments intersecting media
	VolumeSegments mVolumeSegments;          

    // For light path belonging to pixel index [x] it stores
    // where it's light vertices end (begin is at [x-1])
    std::vector<int> mPathEnds;

	// Used algorithm
	AlgorithmType mAlgorithm;

	// Random number generator
    Rng mRng;
};

#endif //__VOLBIDIRPT_HXX__
